{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "from gym_utils import AtariEnv\n",
    "from gym_utils import AtariFrame\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "environment_name = \"SpaceInvaders-v4\"\n",
    "typical_bad_game_frame_count = 1200\n",
    "reward_frame_shift = -15\n",
    "\n",
    "# environment_name = \"Pong-v4\"\n",
    "# typical_bad_game_frame_count = 1100\n",
    "# reward_frame_shift = -1\n",
    "\n",
    "action_count = gym.make(environment_name).action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariModel(nn.Module):\n",
    "\n",
    "    def __init__(self, action_count, dropout=0.25):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch AtariModel Module\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(AtariModel, self).__init__()\n",
    "        self.action_count = action_count\n",
    "        \n",
    "        # convolutional layer 1  (in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
    "        # convolutional layer 2\n",
    "        self.conv2 = nn.Conv2d(32, 128, 3, stride=1, padding=1)\n",
    "        # convolutional layer 3\n",
    "        self.conv3 = nn.Conv2d(128, 512, 3, stride=1, padding=1)\n",
    "\n",
    "        # max pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #then into an RNN\n",
    "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.n_layers = 2\n",
    "        self.hidden_dim = 512\n",
    "        self.lstm = nn.LSTM(512*10*13, self.hidden_dim, self.n_layers, dropout=dropout, batch_first=True)  #10 frames???\n",
    "        \n",
    "        #self.fc1 = nn.Linear(8320*8, 512)  \n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, action_count)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, img_array, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param img_array: The input img array to the neural network\n",
    "        :return\n",
    "        \"\"\"\n",
    "        ## Define forward behavior\n",
    "        #print(\"forward received img_array of shape: {}\".format(img_array.shape))\n",
    "        \n",
    "        batch_size = img_array.size(0)\n",
    "        sequence_length = 5 #### todo - paramertize this\n",
    "        #print(\"batch_size: {}, sequence_length: {}\".format(batch_size, sequence_length))\n",
    "        \n",
    "        #convolutional layers\n",
    "        x = self.maxpool(F.relu(self.conv1(img_array)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "        x = self.maxpool(F.relu(self.conv3(x)))  \n",
    "        \n",
    "        #print(\"x.shape after exiting last max pool: {}\".format(x.shape)) #([1, 512, 10, 13])\n",
    "        \n",
    "        #flatten\n",
    "        x = x.view(-1, 8320*8)  \n",
    "        #print(\"x.view shape: {}\".format(x.shape))  #torch.Size([1, 8320])\n",
    "        \n",
    "        #out_contiguous = x.contiguous().view(-1, batch_size, 512*10*13)  #66560\n",
    "        out_contiguous = x.contiguous().view(-1, sequence_length, 512*10*13)  #66560\n",
    "        \n",
    "        #into LTSM\n",
    "        #print(\"out_contiguous.shape: {}, hidden[0].shape: {}\".format(out_contiguous.shape, hidden[0].shape))\n",
    "\n",
    "        r_out, hidden = self.lstm(out_contiguous, hidden) \n",
    "        \n",
    "        #fc layers\n",
    "        #x = self.dropout(x)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        r_out = self.dropout(r_out)\n",
    "        r_out = F.relu(self.fc2(r_out))\n",
    "        out_fc = self.fc3(r_out)\n",
    "        #print(\"out_fc.shape: {}\".format(out_fc.shape))  #out_fc.shape: torch.Size([50, 5, 6])\n",
    "        #out_reshaped = out_fc.view(batch_size, -1, self.action_count)  # reshape to be batch_size first\n",
    "        #out_reshaped = out_fc.view(-1, self.action_count)  # reshape to be batch_size first\n",
    "        #print(\"out_reshaped is: {}\".format(out_reshaped))\n",
    "        #out = out_reshaped[:, -1] ##### get last batch of labels\n",
    "        out = out_fc[:, -1, :]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        # Implement function\n",
    "        \n",
    "        # initialize hidden state with zero weights, and move to GPU if available\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "       \n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play a game. feed each frame into the model and see what we get\n",
    "def play_game(env_name, model, use_probability_based_action, max_frames=5000):\n",
    "    model.eval()\n",
    "    atari_env = AtariEnv(environment_name, reward_frame_shift)\n",
    "    current_action = 0\n",
    "    done = False\n",
    "    frame_counter = 0\n",
    "    \n",
    "    hidden = model.init_hidden(1) #one batch needed for playing\n",
    "    \n",
    "    while not done:\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "    \n",
    "        atari_frame = atari_env.step(current_action)\n",
    "        img_array = get_play_sequence(atari_env)\n",
    "        img_tensor = torch.from_numpy(img_array).float().cuda()\n",
    "        output, hidden = model(img_tensor, hidden)\n",
    "        #print(\"output: {}\".format(output))\n",
    "        action_array = output.detach().cpu().numpy()[0]\n",
    "        \n",
    "        if use_probability_based_action:\n",
    "            choices = np.arange(0,6)\n",
    "            action_array_softmax = softmax(action_array)\n",
    "            probability_based_action = np.random.choice(choices, p=action_array_softmax)\n",
    "            #print(\"{} - {}\".format(np.argmax(action_array), probability_based_action))\n",
    "\n",
    "            #### use probability_based_action\n",
    "            atari_frame.action_array = action_array_softmax\n",
    "            current_action = probability_based_action\n",
    "        else:\n",
    "            atari_frame.action_array = action_array\n",
    "            current_action = np.argmax(action_array)\n",
    "\n",
    "        done = atari_frame.done_bool\n",
    "        frame_counter += 1\n",
    "        if frame_counter > max_frames:\n",
    "            break\n",
    "\n",
    "    atari_env.close()\n",
    "    return atari_env, hidden\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def get_play_sequence(atari_env, sequence_length=5):\n",
    "    frame_batch = np.zeros((sequence_length, 3, 160, 210))\n",
    "    \n",
    "    for ii in range(-sequence_length, 0):\n",
    "        this_frame_index = len(atari_env.frame_buffer) + ii\n",
    "        if this_frame_index < 0:\n",
    "            this_frame_index = 0\n",
    "        \n",
    "        atari_frame = atari_env.frame_buffer[this_frame_index]\n",
    "        \n",
    "        img_array = atari_frame.img_array\n",
    "        img_array = img_array.reshape((3,160,210))\n",
    "        frame_batch[ii + sequence_length] = img_array\n",
    "        \n",
    "    return frame_batch\n",
    "\n",
    "def get_train_batch(atari_env, batch_size, sequence_length=5):\n",
    "    rand_arr = np.arange(len(atari_env.frame_buffer))\n",
    "    np.random.shuffle(rand_arr)\n",
    "    action_count = atari_env.env.action_space.n\n",
    "    \n",
    "    index_counter = 0\n",
    "    batch_index_counter = 0\n",
    "    frame_batch = np.zeros((batch_size*sequence_length, 3, 160, 210))\n",
    "    target_batch = np.zeros(batch_size)\n",
    "    reward_batch = np.zeros(batch_size)\n",
    "    actions_batch = np.zeros((batch_size, action_count))\n",
    "    \n",
    "    for ii_batch in range(batch_size):\n",
    "        batch_end_index = rand_arr[ii_batch]\n",
    "        \n",
    "        for ii in range(batch_end_index-sequence_length, batch_end_index):\n",
    "            this_frame_index = ii\n",
    "            if this_frame_index < 0:\n",
    "                this_frame_index = 0\n",
    "\n",
    "            #print(\"batch_end_index: {}\".format(batch_end_index))\n",
    "            #print(\"this_frame_index: {}\".format(this_frame_index))\n",
    "            atari_frame = atari_env.frame_buffer[this_frame_index]\n",
    "\n",
    "            img_array = atari_frame.img_array\n",
    "            img_array = img_array.reshape((3,160,210))\n",
    "            frame_batch[index_counter] = img_array\n",
    "      \n",
    "            index_counter += 1\n",
    "\n",
    "        reward = atari_frame.discounted_reward\n",
    "        reward_batch[batch_index_counter] = reward\n",
    "        \n",
    "        ############# todo - update target action with the one we want based on the reward given\n",
    "        \n",
    "        action_array = atari_frame.action_array\n",
    "        train_action = np.argmax(action_array)\n",
    "        if reward < 0.25:\n",
    "            train_action = np.argmin(action_array)\n",
    "            #train_action = action_array.argsort()[:-1][-1] #second largest element\n",
    "        target_batch[batch_index_counter] = train_action\n",
    "\n",
    "        actions_batch[batch_index_counter] = atari_frame.action_array\n",
    "        \n",
    "        batch_index_counter += 1\n",
    "    ############## maybe make sure we don't give too many to one action    \n",
    "    \n",
    "    return frame_batch, target_batch, reward_batch, actions_batch\n",
    "    \n",
    "\n",
    "def train(atari_env, model, optimizer, criterion):\n",
    "    train_batch_size = 50\n",
    "    model.train()\n",
    "    hidden = model.init_hidden(train_batch_size)\n",
    "    #print(\"init hidden[0] shape: {}\".format(hidden[0].shape))\n",
    "    action_count = atari_env.env.action_space.n\n",
    "    discounted_rewards = atari_env.get_discounted_rewards()\n",
    "    frame_buffer = atari_env.frame_buffer\n",
    "    action_tally = np.zeros(action_count)\n",
    "    train_tally = np.zeros(action_count)\n",
    "    \n",
    "#     reward_mean_shift = 0\n",
    "#     if len(discounted_rewards) > typical_bad_game_frame_count:\n",
    "#         sorted_rewards = np.sort(discounted_rewards)\n",
    "#         desired_median = sorted_rewards[typical_bad_game_frame_count//2]\n",
    "#         reward_mean_shift = -1.0 * desired_median\n",
    "#     print(\"shifting rewards by: {:.3f}\".format(reward_mean_shift))\n",
    "    \n",
    "    total_loss = 0\n",
    "    epochs = 25\n",
    "    #for ii, reward_ii in enumerate(discounted_rewards):\n",
    "    for i in range(epochs):\n",
    "    \n",
    "        #print(\"{}: {}\".format(i, reward))\n",
    "        optimizer.zero_grad()\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        frame_batch, target_batch, reward_batch, actions_batch = get_train_batch(atari_env, train_batch_size)\n",
    "        #print(\"get_train_batch. frame_batch: {}, target_batch: {}, reward_batch: {}\".format(frame_batch.shape, target_batch.shape, reward_batch.shape))\n",
    "        \n",
    "        #reward_batch = reward_batch + reward_mean_shift #shift rewards for long games\n",
    "        \n",
    "        #print(\"train frame batch shape: {}\".format(frame_batch.shape))\n",
    "        img_tensor = torch.from_numpy(frame_batch).float().cuda()\n",
    "        output, hidden = model(img_tensor, hidden)\n",
    "\n",
    "        target = torch.from_numpy(target_batch)\n",
    "        #print(\"training target: {}\".format(target))\n",
    "        target = target.long().cuda()\n",
    "        #print(\"output: {}, target: {}\".format(output.shape, target))\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        #print(\"loss: {}\".format(loss))\n",
    "        total_loss += loss\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"avg loss: {:.3f}\".format(total_loss / epochs))\n",
    "#    print(\"model action_tally: {}\".format(action_tally))\n",
    "#    print(\"train_tally:        {}\".format(train_tally))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new model\n",
    "\n",
    "atari_model = AtariModel(action_count)\n",
    "atari_model.cuda()\n",
    "\n",
    "### loss function\n",
    "atari_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0) frames played: 552, score: 15.0\n",
      "actions taken: [ 87.  71.  91. 102.  94. 107.]\n",
      "avg loss: 1.681\n",
      "\n",
      "1) frames played: 438, score: 65.0\n",
      "actions taken: [ 73.  58.  52.  64. 114.  77.]\n",
      "avg loss: 1.716\n",
      "\n",
      "2) frames played: 815, score: 215.0\n",
      "actions taken: [110. 104. 132. 134. 221. 114.]\n",
      "avg loss: 1.729\n",
      "\n",
      "3) frames played: 755, score: 120.0\n",
      "actions taken: [126. 106. 120. 125. 183.  95.]\n",
      "avg loss: 1.756\n",
      "\n",
      "4) frames played: 919, score: 220.0\n",
      "actions taken: [132. 119. 129. 136. 238. 165.]\n",
      "avg loss: 1.716\n",
      "\n",
      "5) frames played: 711, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 710.   0.]\n",
      "avg loss: 1.753\n",
      "\n",
      "6) frames played: 458, score: 80.0\n",
      "actions taken: [ 90.  65.  49.  56. 126.  72.]\n",
      "avg loss: 1.735\n",
      "\n",
      "7) frames played: 766, score: 150.0\n",
      "actions taken: [108. 107. 141.  89. 235.  86.]\n",
      "avg loss: 1.780\n",
      "\n",
      "8) frames played: 676, score: 125.0\n",
      "actions taken: [101.  94. 105.  99. 185.  92.]\n",
      "avg loss: 1.712\n",
      "\n",
      "9) frames played: 631, score: 65.0\n",
      "actions taken: [ 86.  65.  88. 108. 182. 102.]\n",
      "avg loss: 1.822\n",
      "\n",
      "10) frames played: 708, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 707.   0.]\n",
      "avg loss: 1.806\n",
      "\n",
      "11) frames played: 434, score: 50.0\n",
      "actions taken: [ 65.  76.  57.  55. 112.  69.]\n",
      "avg loss: 1.804\n",
      "\n",
      "12) frames played: 347, score: 95.0\n",
      "actions taken: [ 56.  51.  53.  32. 104.  51.]\n",
      "avg loss: 1.740\n",
      "\n",
      "13) frames played: 623, score: 65.0\n",
      "actions taken: [ 84.  96. 103.  88. 174.  78.]\n",
      "avg loss: 1.764\n",
      "\n",
      "14) frames played: 399, score: 10.0\n",
      "actions taken: [ 61.  61.  58.  47. 108.  64.]\n",
      "avg loss: 1.788\n",
      "\n",
      "15) frames played: 730, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 729.   0.]\n",
      "avg loss: 1.739\n",
      "\n",
      "16) frames played: 376, score: 80.0\n",
      "actions taken: [ 55.  44.  64.  52. 104.  57.]\n",
      "avg loss: 1.758\n",
      "\n",
      "17) frames played: 529, score: 50.0\n",
      "actions taken: [ 72.  82.  74.  64. 158.  79.]\n",
      "avg loss: 1.746\n",
      "\n",
      "18) frames played: 500, score: 35.0\n",
      "actions taken: [ 72.  67.  61.  61. 169.  70.]\n",
      "avg loss: 1.755\n",
      "\n",
      "19) frames played: 688, score: 195.0\n",
      "actions taken: [ 96.  88.  95. 110. 217.  82.]\n",
      "avg loss: 1.754\n",
      "\n",
      "20) frames played: 719, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 718.   0.]\n",
      "avg loss: 1.757\n",
      "\n",
      "21) frames played: 445, score: 130.0\n",
      "actions taken: [ 59.  78.  51.  57. 131.  69.]\n",
      "avg loss: 1.722\n",
      "\n",
      "22) frames played: 1566, score: 815.0\n",
      "actions taken: [215. 228. 217. 195. 474. 237.]\n",
      "avg loss: 1.798\n",
      "\n",
      "23) frames played: 633, score: 105.0\n",
      "actions taken: [103. 100.  76. 128. 134.  92.]\n",
      "avg loss: 1.759\n",
      "\n",
      "24) frames played: 630, score: 125.0\n",
      "actions taken: [ 92. 132.  80. 116. 121.  89.]\n",
      "avg loss: 1.828\n",
      "\n",
      "25) frames played: 721, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 720.   0.]\n",
      "avg loss: 1.761\n",
      "\n",
      "26) frames played: 395, score: 55.0\n",
      "actions taken: [ 59.  60.  56.  71. 111.  38.]\n",
      "avg loss: 1.786\n",
      "\n",
      "27) frames played: 354, score: 30.0\n",
      "actions taken: [39. 60. 53. 58. 97. 47.]\n",
      "avg loss: 1.729\n",
      "\n",
      "28) frames played: 496, score: 65.0\n",
      "actions taken: [ 86.  45.  72.  77. 133.  83.]\n",
      "avg loss: 1.767\n",
      "\n",
      "29) frames played: 569, score: 50.0\n",
      "actions taken: [ 88.  77.  72. 101. 151.  80.]\n",
      "avg loss: 1.796\n",
      "\n",
      "30) frames played: 715, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 714.   0.]\n",
      "avg loss: 1.756\n",
      "\n",
      "31) frames played: 494, score: 90.0\n",
      "actions taken: [ 92.  70.  59.  62. 146.  65.]\n",
      "avg loss: 1.766\n",
      "\n",
      "32) frames played: 1022, score: 245.0\n",
      "actions taken: [118. 146. 126. 148. 318. 166.]\n",
      "avg loss: 1.724\n",
      "\n",
      "33) frames played: 470, score: 105.0\n",
      "actions taken: [ 74.  74.  67.  73. 119.  63.]\n",
      "avg loss: 1.739\n",
      "\n",
      "34) frames played: 651, score: 135.0\n",
      "actions taken: [ 95. 107.  71.  94. 178. 106.]\n",
      "avg loss: 1.788\n",
      "\n",
      "35) frames played: 708, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 707.   0.]\n",
      "avg loss: 1.691\n",
      "\n",
      "36) frames played: 809, score: 160.0\n",
      "actions taken: [102. 134. 112. 105. 237. 119.]\n",
      "avg loss: 1.796\n",
      "\n",
      "37) frames played: 430, score: 75.0\n",
      "actions taken: [ 56.  54.  68.  59. 134.  59.]\n",
      "avg loss: 1.798\n",
      "\n",
      "38) frames played: 605, score: 180.0\n",
      "actions taken: [ 88.  98.  68.  89. 171.  91.]\n",
      "avg loss: 1.765\n",
      "\n",
      "39) frames played: 1058, score: 460.0\n",
      "actions taken: [175. 120. 150. 141. 328. 144.]\n",
      "avg loss: 1.847\n",
      "\n",
      "40) frames played: 722, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 721.   0.]\n",
      "avg loss: 1.742\n",
      "\n",
      "41) frames played: 831, score: 170.0\n",
      "actions taken: [119. 124. 129. 136. 209. 114.]\n",
      "avg loss: 1.773\n",
      "\n",
      "42) frames played: 539, score: 100.0\n",
      "actions taken: [ 62.  70.  80.  86. 158.  83.]\n",
      "avg loss: 1.742\n",
      "\n",
      "43) frames played: 778, score: 240.0\n",
      "actions taken: [105. 117. 127. 107. 213. 109.]\n",
      "avg loss: 1.760\n",
      "\n",
      "44) frames played: 456, score: 105.0\n",
      "actions taken: [ 63.  49.  68.  61. 137.  78.]\n",
      "avg loss: 1.729\n",
      "\n",
      "45) frames played: 716, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 715.   0.]\n",
      "avg loss: 1.730\n",
      "\n",
      "46) frames played: 698, score: 160.0\n",
      "actions taken: [ 85.  81. 102. 107. 238.  85.]\n",
      "avg loss: 1.765\n",
      "\n",
      "47) frames played: 731, score: 185.0\n",
      "actions taken: [104. 120. 103. 102. 204.  98.]\n",
      "avg loss: 1.741\n",
      "\n",
      "48) frames played: 392, score: 60.0\n",
      "actions taken: [ 63.  59.  51.  47. 126.  46.]\n",
      "avg loss: 1.739\n",
      "\n",
      "49) frames played: 882, score: 260.0\n",
      "actions taken: [112. 133. 140. 113. 271. 113.]\n",
      "avg loss: 1.694\n",
      "\n",
      "50) frames played: 712, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 711.   0.]\n",
      "avg loss: 1.733\n",
      "\n",
      "51) frames played: 1016, score: 335.0\n",
      "actions taken: [142. 152. 132. 152. 313. 125.]\n",
      "avg loss: 1.716\n",
      "\n",
      "52) frames played: 490, score: 55.0\n",
      "actions taken: [ 74.  73.  63.  65. 159.  56.]\n",
      "avg loss: 1.772\n",
      "\n",
      "53) frames played: 420, score: 65.0\n",
      "actions taken: [ 58.  70.  52.  49. 132.  59.]\n",
      "avg loss: 1.804\n",
      "\n",
      "54) frames played: 370, score: 85.0\n",
      "actions taken: [ 50.  53.  45.  54. 118.  50.]\n",
      "avg loss: 1.756\n",
      "\n",
      "55) frames played: 716, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 715.   0.]\n",
      "avg loss: 1.736\n",
      "\n",
      "56) frames played: 937, score: 370.0\n",
      "actions taken: [145. 151. 131. 114. 278. 118.]\n",
      "avg loss: 1.707\n",
      "\n",
      "57) frames played: 1475, score: 510.0\n",
      "actions taken: [201. 207. 193. 214. 445. 215.]\n",
      "avg loss: 1.686\n",
      "\n",
      "58) frames played: 713, score: 185.0\n",
      "actions taken: [ 92.  96.  93.  86. 250.  96.]\n",
      "avg loss: 1.721\n",
      "\n",
      "59) frames played: 852, score: 460.0\n",
      "actions taken: [145.  93. 116. 108. 295.  95.]\n",
      "avg loss: 1.850\n",
      "\n",
      "60) frames played: 730, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 729.   0.]\n",
      "avg loss: 1.723\n",
      "\n",
      "61) frames played: 668, score: 160.0\n",
      "actions taken: [ 99.  97.  91.  97. 196.  88.]\n",
      "avg loss: 1.748\n",
      "\n",
      "62) frames played: 500, score: 45.0\n",
      "actions taken: [ 85.  62.  78.  71. 134.  70.]\n",
      "avg loss: 1.808\n",
      "\n",
      "63) frames played: 509, score: 50.0\n",
      "actions taken: [ 67.  73.  60.  93. 143.  73.]\n",
      "avg loss: 1.785\n",
      "\n",
      "64) frames played: 676, score: 215.0\n",
      "actions taken: [101.  96. 117.  82. 181.  99.]\n",
      "avg loss: 1.722\n",
      "\n",
      "65) frames played: 719, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 718.   0.]\n",
      "avg loss: 1.704\n",
      "\n",
      "66) frames played: 1113, score: 370.0\n",
      "actions taken: [163. 181. 169. 147. 315. 138.]\n",
      "avg loss: 1.712\n",
      "\n",
      "67) frames played: 522, score: 120.0\n",
      "actions taken: [ 81.  66.  64.  74. 175.  62.]\n",
      "avg loss: 1.705\n",
      "\n",
      "68) frames played: 374, score: 40.0\n",
      "actions taken: [ 58.  54.  44.  47. 121.  50.]\n",
      "avg loss: 1.806\n",
      "\n",
      "69) frames played: 382, score: 35.0\n",
      "actions taken: [ 52.  55.  61.  54. 108.  52.]\n",
      "avg loss: 1.769\n",
      "\n",
      "70) frames played: 721, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 720.   0.]\n",
      "avg loss: 1.703\n",
      "\n",
      "71) frames played: 646, score: 205.0\n",
      "actions taken: [ 98.  87. 101.  90. 196.  74.]\n",
      "avg loss: 1.735\n",
      "\n",
      "72) frames played: 524, score: 125.0\n",
      "actions taken: [ 69.  55.  82.  72. 171.  75.]\n",
      "avg loss: 1.725\n",
      "\n",
      "73) frames played: 509, score: 135.0\n",
      "actions taken: [ 73.  63.  71.  55. 176.  71.]\n",
      "avg loss: 1.718\n",
      "\n",
      "74) frames played: 640, score: 120.0\n",
      "actions taken: [ 82.  91.  97.  86. 210.  74.]\n",
      "avg loss: 1.716\n",
      "\n",
      "75) frames played: 713, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 712.   0.]\n",
      "avg loss: 1.713\n",
      "\n",
      "76) frames played: 392, score: 45.0\n",
      "actions taken: [ 36.  46.  59.  65. 136.  50.]\n",
      "avg loss: 1.784\n",
      "\n",
      "77) frames played: 600, score: 155.0\n",
      "actions taken: [ 75.  82.  85.  82. 204.  72.]\n",
      "avg loss: 1.717\n",
      "\n",
      "78) frames played: 399, score: 110.0\n",
      "actions taken: [ 44.  61.  53.  51. 134.  56.]\n",
      "avg loss: 1.658\n",
      "\n",
      "79) frames played: 995, score: 335.0\n",
      "actions taken: [127. 130. 153. 131. 322. 132.]\n",
      "avg loss: 1.683\n",
      "\n",
      "80) frames played: 722, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 721.   0.]\n",
      "avg loss: 1.715\n",
      "\n",
      "81) frames played: 380, score: 60.0\n",
      "actions taken: [ 51.  51.  51.  42. 138.  47.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss: 1.762\n",
      "\n",
      "82) frames played: 691, score: 295.0\n",
      "actions taken: [100.  80.  96.  92. 234.  89.]\n",
      "avg loss: 1.654\n",
      "\n",
      "83) frames played: 920, score: 295.0\n",
      "actions taken: [104. 108. 111. 104. 348. 145.]\n",
      "avg loss: 1.729\n",
      "\n",
      "84) frames played: 535, score: 130.0\n",
      "actions taken: [ 70.  72.  71.  72. 180.  70.]\n",
      "avg loss: 1.759\n",
      "\n",
      "85) frames played: 721, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 720.   0.]\n",
      "avg loss: 1.705\n",
      "\n",
      "86) frames played: 631, score: 110.0\n",
      "actions taken: [ 71.  91.  91.  88. 215.  75.]\n",
      "avg loss: 1.720\n",
      "\n",
      "87) frames played: 670, score: 155.0\n",
      "actions taken: [ 98.  95.  82.  89. 234.  72.]\n",
      "avg loss: 1.762\n",
      "\n",
      "88) frames played: 355, score: 30.0\n",
      "actions taken: [ 53.  44.  47.  45. 123.  43.]\n",
      "avg loss: 1.743\n",
      "\n",
      "89) frames played: 1423, score: 440.0\n",
      "actions taken: [194. 213. 214. 186. 403. 213.]\n",
      "avg loss: 1.735\n",
      "\n",
      "90) frames played: 725, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 724.   0.]\n",
      "avg loss: 1.736\n",
      "\n",
      "91) frames played: 1089, score: 325.0\n",
      "actions taken: [154. 146. 163. 145. 337. 144.]\n",
      "avg loss: 1.714\n",
      "\n",
      "92) frames played: 431, score: 40.0\n",
      "actions taken: [ 64.  57.  50.  50. 152.  58.]\n",
      "avg loss: 1.742\n",
      "\n",
      "93) frames played: 634, score: 185.0\n",
      "actions taken: [ 82.  69.  87.  93. 214.  89.]\n",
      "avg loss: 1.698\n",
      "\n",
      "94) frames played: 408, score: 90.0\n",
      "actions taken: [ 54.  55.  52.  67. 134.  46.]\n",
      "avg loss: 1.769\n",
      "\n",
      "95) frames played: 716, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 715.   0.]\n",
      "avg loss: 1.726\n",
      "\n",
      "96) frames played: 828, score: 140.0\n",
      "actions taken: [109. 110. 122. 108. 263. 116.]\n",
      "avg loss: 1.735\n",
      "\n",
      "97) frames played: 982, score: 195.0\n",
      "actions taken: [139. 129. 113. 159. 305. 137.]\n",
      "avg loss: 1.771\n",
      "\n",
      "98) frames played: 765, score: 125.0\n",
      "actions taken: [114.  92. 110.  98. 228. 123.]\n",
      "avg loss: 1.719\n",
      "\n",
      "99) frames played: 695, score: 150.0\n",
      "actions taken: [ 82.  84.  99.  90. 232. 108.]\n",
      "avg loss: 1.714\n",
      "\n",
      "100) frames played: 722, score: 270.0\n",
      "actions taken: [  1.   0.   0.   0. 721.   0.]\n",
      "avg loss: 1.690\n"
     ]
    }
   ],
   "source": [
    "### optimizer\n",
    "atari_optimizer = optim.Adam(atari_model.parameters(), lr=0.00001)\n",
    "\n",
    "for i in range(101):\n",
    "    #play a game\n",
    "    use_probability_based_action = i % 5 != 0 or i == 0\n",
    "    atari_env, hidden = play_game(environment_name, atari_model, use_probability_based_action)\n",
    "\n",
    "    #discounted_rewards = atari_env.get_discounted_rewards()\n",
    "    #print()\n",
    "    #print(discounted_rewards)\n",
    "    print(\"\\n{}) frames played: {}, score: {}\".format(i, len(atari_env.frame_buffer), atari_env.get_total_score()))\n",
    "    print(\"actions taken: {}\".format(atari_env.get_actions_taken()))\n",
    "\n",
    "    #train the model\n",
    "    train(atari_env, atari_model, atari_optimizer, atari_criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discounted_rewards mean: 1.9682624259282554e-17\n"
     ]
    }
   ],
   "source": [
    "#display frame\n",
    "frame_num=300\n",
    "discounted_rewards = atari_env.get_discounted_rewards()\n",
    "\n",
    "print(\"discounted_rewards mean: {}\".format(np.mean(discounted_rewards)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame: 304, original reward: 0.259\n",
      "actions out: [-0.13122709 -0.13930713 -0.15244992 -0.19077629  0.7402337  -0.16593331]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_num += 4\n",
    "atari_frame = atari_env.frame_buffer[frame_num]\n",
    "\n",
    "print(\"frame: {}, original reward: {:.3f}\".format(frame_num, discounted_rewards[frame_num]))\n",
    "print(\"actions out: {}\".format(atari_env.frame_buffer[frame_num].action_array))\n",
    "\n",
    "atari_frame.show_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions out: [-0.10772737 -0.11491622 -0.13322502 -0.16233112  0.6505028  -0.14070976]\n",
      "actions out: [-0.12761424 -0.13548182 -0.14949158 -0.18659449  0.7270425  -0.16233411]\n",
      "actions out: [-0.13061234 -0.13865618 -0.15192127 -0.19006531  0.73801756 -0.16537887]\n",
      "actions out: [-0.13111086 -0.13918598 -0.15234472 -0.19063751  0.7398198  -0.16583815]\n",
      "actions out: [-0.13120182 -0.13928115 -0.15242642 -0.19074547  0.74014485 -0.16591382]\n",
      "actions out: [-0.13121992 -0.1392994  -0.15244344 -0.19076796  0.7402085  -0.16592756]\n",
      "actions out: [-0.13122378 -0.13930315 -0.15244722 -0.190773    0.7402219  -0.1659303 ]\n",
      "actions out: [-0.13122456 -0.13930401 -0.15244806 -0.19077419  0.7402247  -0.16593093]\n",
      "actions out: [-0.13122474 -0.13930418 -0.15244824 -0.19077444  0.7402253  -0.16593108]\n",
      "actions out: [-0.13122477 -0.1393042  -0.15244827 -0.19077452  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122487 -0.13930416 -0.15244834 -0.19077456  0.7402256  -0.16593108]\n",
      "actions out: [-0.13122492 -0.13930419 -0.15244839 -0.19077456  0.7402258  -0.1659311 ]\n",
      "actions out: [-0.13122492 -0.13930422 -0.15244837 -0.1907746   0.74022585 -0.1659311 ]\n",
      "actions out: [-0.13122495 -0.13930425 -0.15244842 -0.1907746   0.740226   -0.16593114]\n",
      "actions out: [-0.13122486 -0.13930428 -0.15244836 -0.19077457  0.74022585 -0.16593114]\n",
      "actions out: [-0.13122483 -0.13930427 -0.1524483  -0.19077456  0.7402256  -0.16593114]\n",
      "actions out: [-0.13122492 -0.13930419 -0.15244834 -0.19077457  0.74022573 -0.16593108]\n",
      "actions out: [-0.13122492 -0.1393042  -0.15244836 -0.19077457  0.74022585 -0.1659311 ]\n",
      "actions out: [-0.13122483 -0.13930427 -0.15244833 -0.19077457  0.7402257  -0.1659311 ]\n",
      "actions out: [-0.13122481 -0.13930424 -0.1524483  -0.19077455  0.7402255  -0.1659311 ]\n",
      "actions out: [-0.1312248  -0.13930424 -0.15244827 -0.19077453  0.7402255  -0.1659311 ]\n",
      "actions out: [-0.13122489 -0.13930418 -0.15244833 -0.19077457  0.7402256  -0.16593108]\n",
      "actions out: [-0.13122492 -0.13930419 -0.15244836 -0.19077457  0.74022585 -0.1659311 ]\n",
      "actions out: [-0.13122483 -0.13930425 -0.15244831 -0.19077457  0.7402257  -0.16593114]\n",
      "actions out: [-0.1312248  -0.13930424 -0.1524483  -0.19077455  0.7402255  -0.1659311 ]\n",
      "actions out: [-0.13122478 -0.13930422 -0.15244828 -0.19077455  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122489 -0.13930419 -0.15244833 -0.19077456  0.7402257  -0.16593108]\n",
      "actions out: [-0.13122492 -0.13930418 -0.15244837 -0.19077457  0.7402258  -0.1659311 ]\n",
      "actions out: [-0.13122492 -0.13930422 -0.15244839 -0.1907746   0.7402259  -0.1659311 ]\n",
      "actions out: [-0.13122495 -0.13930425 -0.15244842 -0.1907746   0.740226   -0.16593114]\n",
      "actions out: [-0.13122486 -0.13930428 -0.15244836 -0.19077457  0.74022585 -0.16593114]\n",
      "actions out: [-0.13122483 -0.13930427 -0.15244831 -0.19077456  0.7402256  -0.1659311 ]\n",
      "actions out: [-0.1312248  -0.13930422 -0.15244828 -0.19077453  0.74022543 -0.1659311 ]\n",
      "actions out: [-0.13122489 -0.13930418 -0.15244833 -0.19077457  0.7402257  -0.16593108]\n",
      "actions out: [-0.13122492 -0.13930418 -0.15244837 -0.19077456  0.7402258  -0.16593108]\n",
      "actions out: [-0.13122492 -0.13930424 -0.15244837 -0.19077459  0.74022585 -0.16593114]\n",
      "actions out: [-0.13122483 -0.13930427 -0.15244834 -0.19077457  0.74022573 -0.16593114]\n",
      "actions out: [-0.13122483 -0.13930425 -0.15244831 -0.19077455  0.7402256  -0.1659311 ]\n",
      "actions out: [-0.13122492 -0.13930419 -0.15244834 -0.19077457  0.74022573 -0.1659311 ]\n",
      "actions out: [-0.13122492 -0.13930422 -0.15244836 -0.19077457  0.74022585 -0.1659311 ]\n",
      "actions out: [-0.13122483 -0.13930427 -0.15244831 -0.19077457  0.7402257  -0.16593114]\n",
      "actions out: [-0.1312248  -0.13930424 -0.1524483  -0.19077455  0.74022555 -0.1659311 ]\n",
      "actions out: [-0.1312248  -0.13930422 -0.1524483  -0.19077453  0.74022543 -0.1659311 ]\n",
      "actions out: [-0.13122477 -0.1393042  -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077453  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122766 -0.13930388 -0.15244985 -0.19077538  0.7402322  -0.1659312 ]\n",
      "actions out: [-0.13122568 -0.13930522 -0.15244922 -0.19077526  0.7402304  -0.16593185]\n",
      "actions out: [-0.13122599 -0.13930501 -0.15244915 -0.19077514  0.74023    -0.16593185]\n",
      "actions out: [-0.13122545 -0.13930501 -0.15244882 -0.19077496  0.7402286  -0.16593179]\n",
      "actions out: [-0.13122527 -0.1393048  -0.15244862 -0.19077483  0.74022746 -0.16593158]\n",
      "actions out: [-0.13122492 -0.13930437 -0.15244839 -0.19077463  0.7402261  -0.16593122]\n",
      "actions out: [-0.1312253  -0.13930422 -0.1524486  -0.19077471  0.74022675 -0.16593117]\n",
      "actions out: [-0.13122496 -0.13930437 -0.15244845 -0.19077466  0.74022627 -0.16593122]\n",
      "actions out: [-0.13122493 -0.13930432 -0.15244839 -0.19077462  0.7402261  -0.16593117]\n",
      "actions out: [-0.13122499 -0.1393043  -0.15244842 -0.1907746   0.7402261  -0.16593117]\n",
      "actions out: [-0.13122615 -0.13930416 -0.15244906 -0.19077496  0.74022883 -0.16593122]\n",
      "actions out: [-0.13122521 -0.13930471 -0.15244871 -0.19077487  0.74022776 -0.16593146]\n",
      "actions out: [-0.13122511 -0.13930462 -0.15244855 -0.19077472  0.7402269  -0.16593143]\n",
      "actions out: [-0.131225   -0.13930449 -0.15244845 -0.19077466  0.74022645 -0.16593131]\n",
      "actions out: [-0.13122493 -0.13930438 -0.15244839 -0.19077463  0.74022603 -0.16593122]\n",
      "actions out: [-0.1312248  -0.13930422 -0.1524483  -0.19077453  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244825 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244825 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122478 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122483 -0.13930419 -0.1524483  -0.19077455  0.7402255  -0.16593108]\n",
      "actions out: [-0.1312248  -0.1393042  -0.15244827 -0.19077453  0.74022543 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.74022543 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122478 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244824 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.1907745   0.74022526 -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122478 -0.13930418 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122617 -0.13930404 -0.15244903 -0.19077493  0.7402287  -0.1659311 ]\n",
      "actions out: [-0.1312255  -0.13930467 -0.15244886 -0.19077496  0.7402284  -0.16593146]\n",
      "actions out: [-0.13124885 -0.13930233 -0.1524615  -0.19078182  0.74028367 -0.16593257]\n",
      "actions out: [-0.13123602 -0.13931285 -0.15245813 -0.19078182  0.740276   -0.16593823]\n",
      "actions out: [-0.13124333 -0.1393119  -0.15246065 -0.19078271  0.74028724 -0.16593903]\n",
      "actions out: [-0.13125315 -0.13931291 -0.15246649 -0.19078639  0.74031466 -0.16594085]\n",
      "actions out: [-0.13128996 -0.1393141  -0.15248804 -0.19079907  0.74041265 -0.16594592]\n",
      "actions out: [-0.13130961 -0.1393269  -0.15250447 -0.19081081  0.7404955  -0.16595685]\n",
      "actions out: [-0.13128157 -0.13934693 -0.15249321 -0.19080727  0.7404601  -0.16596833]\n",
      "actions out: [-0.13141777 -0.13932872 -0.15256257 -0.19084331  0.740762   -0.16597268]\n",
      "actions out: [-0.13134637 -0.13938594 -0.15254344 -0.19084342  0.74071586 -0.16600272]\n",
      "actions out: [-0.13129207 -0.1393869  -0.15250567 -0.19081986  0.7405482  -0.16600004]\n",
      "actions out: [-0.13127068 -0.13935986 -0.15248218 -0.19080149  0.7404248  -0.1659798 ]\n",
      "actions out: [-0.13125563 -0.13934113 -0.15246896 -0.19079228  0.74035126 -0.16596353]\n",
      "actions out: [-0.13123587 -0.1393143  -0.15245523 -0.19077934  0.74026453 -0.16594091]\n",
      "actions out: [-0.1312261  -0.13930474 -0.15244922 -0.19077523  0.7402298  -0.16593131]\n",
      "actions out: [-0.13122441 -0.13930361 -0.15244803 -0.19077457  0.7402245  -0.16593021]\n",
      "actions out: [-0.13122432 -0.13930371 -0.1524479  -0.19077446  0.7402242  -0.16593042]\n",
      "actions out: [-0.13122444 -0.13930386 -0.15244795 -0.19077446  0.7402244  -0.16593069]\n",
      "actions out: [-0.13122475 -0.13930403 -0.15244818 -0.1907744   0.74022514 -0.16593096]\n",
      "actions out: [-0.13122483 -0.13930395 -0.15244827 -0.19077437  0.7402253  -0.16593099]\n",
      "actions out: [-0.1312247  -0.13930406 -0.15244824 -0.19077449  0.7402252  -0.16593096]\n",
      "actions out: [-0.13122474 -0.1393041  -0.15244822 -0.1907745   0.74022526 -0.16593096]\n",
      "actions out: [-0.13122472 -0.13930413 -0.15244824 -0.19077452  0.7402252  -0.16593099]\n",
      "actions out: [-0.13122474 -0.13930413 -0.15244825 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.1312248  -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122539 -0.13930412 -0.15244861 -0.19077472  0.7402269  -0.1659311 ]\n",
      "actions out: [-0.13122787 -0.1393041  -0.15245005 -0.19077554  0.74023336 -0.16593137]\n",
      "actions out: [-0.13122597 -0.13930541 -0.15244943 -0.1907754   0.74023145 -0.16593206]\n",
      "actions out: [-0.13130088 -0.13929756 -0.15248987 -0.19079728  0.74040836 -0.16593531]\n",
      "actions out: [-0.13132574 -0.13932441 -0.152515   -0.19081675  0.7405404  -0.1659562 ]\n",
      "actions out: [-0.1314901  -0.13933198 -0.15260985 -0.1908711   0.7409756  -0.16598177]\n",
      "actions out: [-0.13221656 -0.13931368 -0.15305881 -0.19107439  0.74306995 -0.16607788]\n",
      "actions out: [-0.1324592  -0.13962059 -0.15334255 -0.1912986   0.74485683 -0.16628191]\n",
      "actions out: [-0.13260502 -0.13989227 -0.15350577 -0.19143175  0.7459251  -0.16648111]\n",
      "actions out: [-0.13189457 -0.14021583 -0.15311468 -0.19118011  0.74410146 -0.16672522]\n",
      "actions out: [-0.13173863 -0.14000493 -0.15285753 -0.19105543  0.742746   -0.16654629]\n",
      "actions out: [-0.13155761 -0.13972288 -0.15267742 -0.19096552  0.7416273  -0.16628978]\n",
      "actions out: [-0.13138303 -0.13950165 -0.15255295 -0.19086878  0.74085724 -0.1660983 ]\n",
      "actions out: [-0.13125347 -0.13934168 -0.15246907 -0.19079606  0.74033064 -0.16595939]\n",
      "actions out: [-0.13122906 -0.13931064 -0.15245242 -0.19077873  0.7402409  -0.16593543]\n",
      "actions out: [-0.13122542 -0.13930531 -0.15244913 -0.19077532  0.74022776 -0.16593179]\n",
      "actions out: [-0.13122489 -0.13930435 -0.15244845 -0.19077468  0.74022573 -0.16593117]\n",
      "actions out: [-0.1312248  -0.1393042  -0.1524483  -0.19077455  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122517 -0.13930415 -0.1524485  -0.19077463  0.7402263  -0.16593108]\n",
      "actions out: [-0.1312252  -0.13930432 -0.15244856 -0.1907747   0.7402268  -0.1659312 ]\n",
      "actions out: [-0.13122572 -0.13930434 -0.15244886 -0.19077487  0.7402281  -0.16593131]\n",
      "actions out: [-0.13122554 -0.13930461 -0.15244883 -0.19077493  0.74022824 -0.16593143]\n",
      "actions out: [-0.13122532 -0.13930468 -0.15244871 -0.19077484  0.74022764 -0.1659315 ]\n",
      "actions out: [-0.13122605 -0.13930449 -0.15244903 -0.19077502  0.74022907 -0.16593143]\n",
      "actions out: [-0.13122605 -0.13930471 -0.15244915 -0.19077511  0.74022967 -0.16593158]\n",
      "actions out: [-0.13123393 -0.13930398 -0.15245347 -0.19077748  0.7402486  -0.16593203]\n",
      "actions out: [-0.13123193 -0.1393074  -0.15245359 -0.19077818  0.74025166 -0.16593409]\n",
      "actions out: [-0.13122885 -0.13930859 -0.15245178 -0.19077723  0.74024457 -0.16593477]\n",
      "actions out: [-0.1312337  -0.1393071  -0.15245378 -0.19077809  0.7402527  -0.16593435]\n",
      "actions out: [-0.13122934 -0.13930881 -0.15245199 -0.19077748  0.74024576 -0.16593495]\n",
      "actions out: [-0.13122742 -0.13930729 -0.15245037 -0.19077621  0.7402372  -0.1659337 ]\n",
      "actions out: [-0.13122629 -0.13930604 -0.15244938 -0.19077547  0.74023193 -0.16593266]\n",
      "actions out: [-0.13122576 -0.13930541 -0.15244895 -0.19077513  0.7402294  -0.16593215]\n",
      "actions out: [-0.13122503 -0.1393045  -0.15244845 -0.19077471  0.7402263  -0.16593131]\n",
      "actions out: [-0.13122483 -0.13930425 -0.15244831 -0.19077455  0.7402256  -0.1659311 ]\n",
      "actions out: [-0.13122489 -0.13930419 -0.15244833 -0.19077457  0.74022573 -0.16593108]\n",
      "actions out: [-0.13122483 -0.13930424 -0.15244831 -0.19077455  0.7402256  -0.1659311 ]\n",
      "actions out: [-0.13122492 -0.1393042  -0.15244839 -0.19077459  0.74022585 -0.1659311 ]\n",
      "actions out: [-0.13122484 -0.13930427 -0.15244833 -0.19077457  0.74022573 -0.16593114]\n",
      "actions out: [-0.13122484 -0.13930424 -0.15244831 -0.19077457  0.7402256  -0.1659311 ]\n",
      "actions out: [-0.13122481 -0.13930424 -0.1524483  -0.19077455  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122478 -0.1393042  -0.15244827 -0.19077453  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122484 -0.13930418 -0.15244833 -0.19077455  0.7402256  -0.16593108]\n",
      "actions out: [-0.13122554 -0.13930413 -0.1524487  -0.19077475  0.7402273  -0.1659311 ]\n",
      "actions out: [-0.131229   -0.13930407 -0.1524507  -0.19077592  0.7402362  -0.1659315 ]\n",
      "actions out: [-0.13124011 -0.13930447 -0.1524573  -0.19077978  0.74026626 -0.16593301]\n",
      "actions out: [-0.13187964 -0.1392375  -0.15280956 -0.19095539  0.7418222  -0.16596565]\n",
      "actions out: [-0.13145761 -0.13954423 -0.15268087 -0.19094123  0.7414527  -0.1661222 ]\n",
      "actions out: [-0.13139834 -0.13952091 -0.15259512 -0.19088452  0.74105877 -0.16611314]\n",
      "actions out: [-0.13135399 -0.13946551 -0.15254146 -0.19084938  0.74078745 -0.16607124]\n",
      "actions out: [-0.13131724 -0.13941799 -0.1525088  -0.19082792  0.74060065 -0.16603005]\n",
      "actions out: [-0.13124363 -0.13932794 -0.15246117 -0.19078784  0.74029523 -0.16594964]\n",
      "actions out: [-0.13122775 -0.13930835 -0.15245089 -0.1907772   0.7402362  -0.16593397]\n",
      "actions out: [-0.13122539 -0.13930497 -0.15244892 -0.19077511  0.74022764 -0.16593161]\n",
      "actions out: [-0.13122493 -0.13930441 -0.15244846 -0.19077468  0.74022603 -0.16593122]\n",
      "actions out: [-0.13122484 -0.13930425 -0.15244836 -0.19077459  0.7402257  -0.16593114]\n",
      "actions out: [-0.13122483 -0.13930425 -0.1524483  -0.19077456  0.74022555 -0.1659311 ]\n",
      "actions out: [-0.1312248  -0.13930424 -0.1524483  -0.19077453  0.74022543 -0.1659311 ]\n",
      "actions out: [-0.1312248  -0.13930418 -0.1524483  -0.19077455  0.7402255  -0.16593108]\n",
      "actions out: [-0.1312248  -0.13930419 -0.15244827 -0.19077452  0.74022543 -0.16593108]\n",
      "actions out: [-0.1312248  -0.13930419 -0.15244827 -0.19077455  0.74022543 -0.16593108]\n",
      "actions out: [-0.1312248  -0.13930419 -0.15244828 -0.19077452  0.74022543 -0.16593105]\n",
      "actions out: [-0.13219719 -0.13918465 -0.15299726 -0.19102107  0.742653   -0.16598141]\n",
      "actions out: [-0.1324036  -0.13954484 -0.15329647 -0.1912611   0.74457043 -0.16622213]\n",
      "actions out: [-0.1325626  -0.13984743 -0.15347488 -0.19140391  0.74573225 -0.16644642]\n",
      "actions out: [-0.13271406 -0.14004812 -0.15359238 -0.1915024   0.7465167  -0.16660494]\n",
      "actions out: [-0.1328243  -0.14018859 -0.15367344 -0.19157581  0.74702424 -0.16671279]\n",
      "actions out: [-0.13288976 -0.14020996 -0.15372007 -0.19161509  0.74723923 -0.16671568]\n",
      "actions out: [-0.1328864  -0.14023261 -0.1537293  -0.19162329  0.7472971  -0.16673046]\n",
      "actions out: [-0.13249876 -0.14028169 -0.15348667 -0.19143002  0.74612087 -0.16683212]\n",
      "actions out: [-0.1326466  -0.14009733 -0.1534804  -0.19142051  0.74601847 -0.16671214]\n",
      "actions out: [-0.13241245 -0.1401004  -0.15337089 -0.19133832  0.7453241  -0.16670254]\n",
      "actions out: [-0.13195816 -0.14008717 -0.1530595  -0.1911587   0.7437448  -0.16663757]\n",
      "actions out: [-0.13165183 -0.13986133 -0.15279429 -0.19102748  0.74228066 -0.16641185]\n",
      "actions out: [-0.13159685 -0.13963565 -0.15269633 -0.1909661   0.74162567 -0.16622755]\n",
      "actions out: [-0.13141984 -0.13949975 -0.15258765 -0.19088914  0.7410058  -0.16609854]\n",
      "actions out: [-0.1314073  -0.13938603 -0.15256587 -0.19085704  0.74081004 -0.16601205]\n",
      "actions out: [-0.1314001  -0.13937461 -0.15256779 -0.1908556   0.7408121  -0.16600147]\n",
      "actions out: [-0.13131365 -0.13940136 -0.15252432 -0.19083406  0.74064106 -0.16601175]\n",
      "actions out: [-0.13128898 -0.13937286 -0.15249662 -0.19081236  0.740498   -0.16599062]\n",
      "actions out: [-0.13127993 -0.13935179 -0.15248542 -0.19080354  0.7404329  -0.16597411]\n",
      "actions out: [-0.13130291 -0.13932958 -0.15249601 -0.1908067   0.7404608  -0.1659593 ]\n",
      "actions out: [-0.13139547 -0.13931973 -0.15255131 -0.19083671  0.7407     -0.16596156]\n",
      "actions out: [-0.13162579 -0.1393413  -0.15269332 -0.19092034  0.7413581  -0.16600311]\n",
      "actions out: [-0.1313775  -0.13948613 -0.15259662 -0.19088937  0.74102753 -0.16607559]\n",
      "actions out: [-0.13134219 -0.13945058 -0.1525419  -0.19084744  0.7407666  -0.16605598]\n",
      "actions out: [-0.13130803 -0.13940641 -0.15250652 -0.19082323  0.74057734 -0.16602015]\n",
      "actions out: [-0.13127784 -0.13936347 -0.15248269 -0.19080488  0.74043113 -0.16598278]\n",
      "actions out: [-0.13123508 -0.13931632 -0.15245599 -0.1907821   0.74026465 -0.16594031]\n",
      "actions out: [-0.13122785 -0.13930778 -0.1524509  -0.19077682  0.7402378  -0.16593385]\n",
      "actions out: [-0.13122621 -0.13930601 -0.15244946 -0.19077553  0.74023163 -0.16593257]\n",
      "actions out: [-0.13122569 -0.13930525 -0.15244892 -0.19077508  0.74022907 -0.165932  ]\n",
      "actions out: [-0.13122505 -0.13930453 -0.1524485  -0.19077472  0.74022657 -0.16593134]\n",
      "actions out: [-0.13122544 -0.13930427 -0.15244865 -0.19077475  0.7402271  -0.1659312 ]\n",
      "actions out: [-0.13122737 -0.13930418 -0.15244979 -0.19077541  0.74023217 -0.16593137]\n",
      "actions out: [-0.13122676 -0.13930513 -0.15244977 -0.19077556  0.7402328  -0.16593194]\n",
      "actions out: [-0.13122718 -0.13930531 -0.15244995 -0.19077566  0.7402338  -0.16593218]\n",
      "actions out: [-0.13122621 -0.13930562 -0.15244943 -0.19077542  0.74023175 -0.1659323 ]\n",
      "actions out: [-0.13122755 -0.13930517 -0.15245    -0.19077568  0.74023396 -0.16593215]\n",
      "actions out: [-0.13122597 -0.13930547 -0.1524493  -0.19077533  0.740231   -0.16593215]\n",
      "actions out: [-0.13122557 -0.1393051  -0.1524489  -0.190775    0.74022883 -0.16593185]\n",
      "actions out: [-0.13122569 -0.13930467 -0.15244886 -0.19077493  0.7402284  -0.16593155]\n",
      "actions out: [-0.13122617 -0.13930462 -0.15244915 -0.19077511  0.7402296  -0.16593152]\n",
      "actions out: [-0.13122615 -0.13930465 -0.1524492  -0.19077517  0.74023    -0.16593155]\n",
      "actions out: [-0.13122542 -0.13930492 -0.15244886 -0.19077496  0.74022853 -0.16593167]\n",
      "actions out: [-0.13122527 -0.13930479 -0.15244865 -0.19077481  0.7402275  -0.16593158]\n",
      "actions out: [-0.13122512 -0.13930456 -0.1524485  -0.19077471  0.74022675 -0.1659314 ]\n",
      "actions out: [-0.13122496 -0.13930435 -0.15244842 -0.19077463  0.7402261  -0.16593122]\n",
      "actions out: [-0.13122483 -0.13930422 -0.15244833 -0.19077453  0.7402256  -0.16593108]\n",
      "actions out: [-0.13122499 -0.13930418 -0.15244842 -0.1907746   0.740226   -0.16593108]\n",
      "actions out: [-0.13122492 -0.13930427 -0.15244842 -0.1907746   0.740226   -0.16593114]\n",
      "actions out: [-0.13122489 -0.13930427 -0.15244836 -0.1907746   0.74022585 -0.16593114]\n",
      "actions out: [-0.13122489 -0.13930425 -0.15244836 -0.19077457  0.74022585 -0.16593114]\n",
      "actions out: [-0.13122483 -0.13930425 -0.15244831 -0.19077456  0.7402256  -0.16593114]\n",
      "actions out: [-0.1312248  -0.13930422 -0.1524483  -0.19077455  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077453  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.1312248  -0.13930416 -0.15244828 -0.19077453  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122481 -0.13930416 -0.15244831 -0.19077453  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122478 -0.13930419 -0.15244828 -0.19077453  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122478 -0.1393042  -0.15244828 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122478 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244828 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244828 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244828 -0.19077452  0.7402254  -0.16593102]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244828 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930419 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930413 -0.15244825 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930413 -0.15244825 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930415 -0.15244825 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930415 -0.15244827 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122472 -0.13930415 -0.15244824 -0.19077446  0.74022526 -0.16593102]\n",
      "actions out: [-0.1312247  -0.13930412 -0.15244824 -0.19077443  0.7402252  -0.16593105]\n",
      "actions out: [-0.13122469 -0.13930412 -0.15244824 -0.19077443  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122472 -0.13930412 -0.15244824 -0.19077443  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122474 -0.1393041  -0.15244824 -0.19077447  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122474 -0.13930413 -0.15244824 -0.19077447  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122472 -0.13930415 -0.15244824 -0.19077446  0.74022526 -0.16593105]\n",
      "actions out: [-0.1312247  -0.13930413 -0.15244824 -0.19077443  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122469 -0.13930412 -0.15244824 -0.19077443  0.7402252  -0.16593105]\n",
      "actions out: [-0.1312247  -0.13930413 -0.15244824 -0.19077444  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122474 -0.13930413 -0.15244824 -0.19077447  0.74022526 -0.16593105]\n",
      "actions out: [-0.1312247  -0.1393041  -0.15244824 -0.19077446  0.74022526 -0.16593105]\n",
      "actions out: [-0.1312247  -0.13930412 -0.15244824 -0.19077443  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122469 -0.13930412 -0.15244824 -0.19077443  0.7402252  -0.16593105]\n",
      "actions out: [-0.13122472 -0.13930413 -0.15244822 -0.19077444  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122474 -0.13930412 -0.15244824 -0.19077446  0.74022526 -0.16593105]\n",
      "actions out: [-0.1312247  -0.13930412 -0.15244824 -0.19077446  0.74022526 -0.16593105]\n",
      "actions out: [-0.1312247  -0.13930412 -0.15244824 -0.19077443  0.7402252  -0.16593102]\n",
      "actions out: [-0.13122453 -0.13930139 -0.1524496  -0.1907721   0.7402232  -0.1659298 ]\n",
      "actions out: [-0.13122456 -0.13930276 -0.15244946 -0.19077452  0.74022424 -0.16593039]\n",
      "actions out: [-0.13122469 -0.13930337 -0.15244907 -0.19077478  0.74022466 -0.1659306 ]\n",
      "actions out: [-0.1312247  -0.13930368 -0.15244879 -0.19077475  0.74022484 -0.16593075]\n",
      "actions out: [-0.13122474 -0.13930386 -0.15244862 -0.1907747   0.74022496 -0.16593084]\n",
      "actions out: [-0.13122474 -0.13930409 -0.15244834 -0.19077452  0.74022526 -0.16593099]\n",
      "actions out: [-0.13122477 -0.13930415 -0.1524483  -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077453  0.74022526 -0.16593105]\n",
      "actions out: [-0.13121419 -0.13929448 -0.15244156 -0.19077168  0.74019456 -0.16592374]\n",
      "actions out: [-0.13214119 -0.13919036 -0.15295881 -0.19100747  0.742492   -0.16597772]\n",
      "actions out: [-0.13186282 -0.13960573 -0.15296327 -0.19106202  0.74284875 -0.16624111]\n",
      "actions out: [-0.1318238  -0.13971324 -0.15291804 -0.19104919  0.7427437  -0.16632813]\n",
      "actions out: [-0.13160115 -0.13974306 -0.15276134 -0.19099434  0.74203557 -0.16631392]\n",
      "actions out: [-0.13150136 -0.13964786 -0.15265027 -0.19093977  0.74143714 -0.1662257 ]\n",
      "actions out: [-0.13136916 -0.13947268 -0.15254739 -0.19085984  0.7408086  -0.16607562]\n",
      "actions out: [-0.1315789  -0.13934734 -0.1526499  -0.19089817  0.74116695 -0.16600564]\n",
      "actions out: [-0.13133945 -0.13942988 -0.15255961 -0.19086187  0.74080986 -0.16602898]\n",
      "actions out: [-0.13130446 -0.13940261 -0.15251501 -0.19082575  0.7406003  -0.16601393]\n",
      "actions out: [-0.13138862 -0.1393648  -0.15254761 -0.19083984  0.7407271  -0.16599804]\n",
      "actions out: [-0.13129835 -0.13939282 -0.15250948 -0.1908254   0.7405725  -0.16600427]\n",
      "actions out: [-0.13125874 -0.13934669 -0.1524755  -0.1907969   0.7403782  -0.16596642]\n",
      "actions out: [-0.1312455  -0.13933022 -0.15246335 -0.19078718  0.74031395 -0.16595349]\n",
      "actions out: [-0.13123904 -0.13932168 -0.15245768 -0.19078302  0.7402827  -0.16594627]\n",
      "actions out: [-0.13122709 -0.13930713 -0.15244992 -0.19077629  0.7402337  -0.16593331]\n",
      "actions out: [-0.13122512 -0.13930468 -0.15244861 -0.19077487  0.74022657 -0.16593137]\n",
      "actions out: [-0.1312248  -0.13930427 -0.15244833 -0.19077457  0.7402255  -0.1659311 ]\n",
      "actions out: [-0.13122477 -0.13930419 -0.1524483  -0.19077453  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244824 -0.19077449  0.7402252  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930418 -0.15244824 -0.19077449  0.7402252  -0.16593102]\n",
      "actions out: [-0.13122474 -0.13930415 -0.15244827 -0.19077449  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930424 -0.1524482  -0.1907745   0.74022514 -0.16593099]\n",
      "actions out: [-0.13122472 -0.13930413 -0.15244824 -0.19077446  0.74022514 -0.16593096]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244825 -0.19077447  0.74022514 -0.16593099]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077449  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077449  0.7402253  -0.16593102]\n",
      "actions out: [-0.13122441 -0.13930383 -0.15244803 -0.19077441  0.74022424 -0.16593078]\n",
      "actions out: [-0.13122362 -0.13930309 -0.15244749 -0.19077425  0.7402219  -0.16593027]\n",
      "actions out: [-0.13120303 -0.13928428 -0.15243419 -0.19076899  0.7401618  -0.16591614]\n",
      "actions out: [-0.13121638 -0.13929348 -0.15244082 -0.19077383  0.74019253 -0.16592506]\n",
      "actions out: [-0.13062485 -0.13875785 -0.152058   -0.19061531  0.7384752  -0.16551957]\n",
      "actions out: [-0.13081186 -0.13884468 -0.15212542 -0.19070448  0.7387922  -0.16563961]\n",
      "actions out: [-0.13100576 -0.13905488 -0.15225048 -0.19076335  0.7393959  -0.16578713]\n",
      "actions out: [-0.1310837  -0.13916506 -0.15232006 -0.19076747  0.7397128  -0.16584888]\n",
      "actions out: [-0.13113318 -0.13922268 -0.15236633 -0.19076471  0.7399027  -0.1658827 ]\n",
      "actions out: [-0.1311976  -0.13928123 -0.15242541 -0.19076724  0.7401308  -0.16591781]\n",
      "actions out: [-0.13122112 -0.13930123 -0.15244567 -0.19077192  0.74021256 -0.16592947]\n",
      "actions out: [-0.13122416 -0.1393037  -0.15244783 -0.19077395  0.7402232  -0.16593081]\n",
      "actions out: [-0.13122466 -0.13930407 -0.15244816 -0.19077437  0.7402249  -0.16593099]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244825 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122483 -0.13930415 -0.15244831 -0.19077455  0.7402255  -0.16593105]\n",
      "actions out: [-0.13122481 -0.13930419 -0.1524483  -0.19077455  0.74022555 -0.16593108]\n",
      "actions out: [-0.13122478 -0.13930419 -0.15244828 -0.19077452  0.74022543 -0.16593108]\n",
      "actions out: [-0.1312248  -0.1393042  -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.1312248  -0.13930419 -0.15244828 -0.19077453  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.74022543 -0.16593105]\n",
      "actions out: [-0.13122481 -0.13930412 -0.15244828 -0.19077447  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930415 -0.15244827 -0.1907745   0.7402254  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077449  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077453  0.7402253  -0.16593105]\n",
      "actions out: [-0.1312248  -0.13930416 -0.15244828 -0.19077453  0.74022543 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244828 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244828 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122483 -0.13930409 -0.15244827 -0.19077446  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930412 -0.15244825 -0.19077449  0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930412 -0.15244825 -0.19077449  0.7402253  -0.16593102]\n",
      "actions out: [-0.13122474 -0.13930415 -0.15244825 -0.19077452  0.7402253  -0.16593099]\n",
      "actions out: [-0.13122474 -0.13930413 -0.15244825 -0.19077452  0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930419 -0.15244825 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244828 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122481 -0.13930416 -0.15244831 -0.19077452  0.74022555 -0.16593105]\n",
      "actions out: [-0.13122477 -0.1393042  -0.1524483  -0.19077455  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122483 -0.13930418 -0.1524483  -0.19077455  0.7402256  -0.16593108]\n",
      "actions out: [-0.1312248  -0.1393042  -0.1524483  -0.19077455  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122478 -0.13930422 -0.1524483  -0.19077453  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.1393042  -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077447  0.74022526 -0.16593105]\n",
      "actions out: [-0.1312247  -0.13930416 -0.15244824 -0.19077446  0.7402252  -0.16593102]\n",
      "actions out: [-0.13122462 -0.13930415 -0.15244818 -0.1907744   0.740225   -0.16593096]\n",
      "actions out: [-0.13122469 -0.13930412 -0.1524482  -0.19077443  0.74022514 -0.16593099]\n",
      "actions out: [-0.1312247  -0.13930415 -0.15244822 -0.19077446  0.74022514 -0.16593102]\n",
      "actions out: [-0.1312247  -0.13930416 -0.15244824 -0.19077446  0.74022514 -0.16593102]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244824 -0.19077447  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930419 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244824 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077449  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077452  0.74022526 -0.16593108]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244825 -0.19077452  0.74022526 -0.16593108]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244827 -0.19077453  0.74022526 -0.16593108]\n",
      "actions out: [-0.13122474 -0.13930418 -0.15244827 -0.19077453  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244825 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13123165 -0.13930348 -0.152452   -0.19077656  0.7402417  -0.16593137]\n",
      "actions out: [-0.13122708 -0.13930666 -0.1524506  -0.19077633  0.74023753 -0.16593298]\n",
      "actions out: [-0.13122672 -0.13930634 -0.15244986 -0.1907757   0.7402342  -0.16593292]\n",
      "actions out: [-0.13122614 -0.13930587 -0.1524493  -0.19077535  0.7402314  -0.16593254]\n",
      "actions out: [-0.13122621 -0.13930535 -0.15244919 -0.19077526  0.7402305  -0.16593215]\n",
      "actions out: [-0.1312253  -0.13930458 -0.15244865 -0.19077483  0.7402274  -0.1659314 ]\n",
      "actions out: [-0.131225   -0.13930446 -0.15244848 -0.19077468  0.74022645 -0.16593128]\n",
      "actions out: [-0.13123067 -0.13930379 -0.15245152 -0.1907763   0.7402397  -0.16593146]\n",
      "actions out: [-0.13122831 -0.13930622 -0.1524511  -0.19077654  0.7402396  -0.16593286]\n",
      "actions out: [-0.13122834 -0.13930644 -0.15245089 -0.19077636  0.74023896 -0.16593313]\n",
      "actions out: [-0.13122673 -0.13930659 -0.15244988 -0.19077583  0.7402347  -0.16593313]\n",
      "actions out: [-0.13122623 -0.139306   -0.15244931 -0.19077541  0.7402316  -0.16593263]\n",
      "actions out: [-0.13122539 -0.13930497 -0.15244871 -0.19077492  0.74022794 -0.16593173]\n",
      "actions out: [-0.13122503 -0.1393045  -0.15244846 -0.19077466  0.74022645 -0.16593134]\n",
      "actions out: [-0.1312248  -0.13930424 -0.15244831 -0.19077455  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077455  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122486 -0.13930415 -0.15244833 -0.19077457  0.74022555 -0.16593108]\n",
      "actions out: [-0.13122483 -0.13930419 -0.15244833 -0.19077456  0.7402256  -0.16593108]\n",
      "actions out: [-0.1312248  -0.13930424 -0.1524483  -0.19077453  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122486 -0.13930419 -0.1524483  -0.19077455  0.7402256  -0.16593108]\n",
      "actions out: [-0.1312248  -0.13930424 -0.1524483  -0.19077455  0.7402255  -0.1659311 ]\n",
      "actions out: [-0.1312248  -0.13930422 -0.1524483  -0.19077455  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122478 -0.13930419 -0.15244828 -0.19077452  0.74022543 -0.16593108]\n",
      "actions out: [-0.13122478 -0.1393042  -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122478 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930416 -0.15244827 -0.19077449  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244828 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122478 -0.13930418 -0.15244828 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122481 -0.13930416 -0.1524483  -0.19077455  0.7402255  -0.16593105]\n",
      "actions out: [-0.13122478 -0.1393042  -0.15244828 -0.19077452  0.7402255  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244828 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930415 -0.15244828 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930415 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.13122475 -0.13930415 -0.15244825 -0.1907745   0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930419 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122599 -0.13930397 -0.152449   -0.19077481  0.74022835 -0.16593102]\n",
      "actions out: [-0.13122395 -0.13930416 -0.1524485  -0.19077404  0.7402256  -0.16593066]\n",
      "actions out: [-0.1312242  -0.13930386 -0.152448   -0.19077404  0.7402248  -0.16593072]\n",
      "actions out: [-0.13122448 -0.13930391 -0.15244803 -0.19077419  0.7402249  -0.16593081]\n",
      "actions out: [-0.1312246  -0.139304   -0.15244809 -0.19077428  0.7402249  -0.1659309 ]\n",
      "actions out: [-0.13122459 -0.13930394 -0.15244806 -0.19077432  0.7402247  -0.16593087]\n",
      "actions out: [-0.13122472 -0.13930412 -0.15244822 -0.19077446  0.74022514 -0.16593102]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077449  0.74022526 -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077449  0.7402253  -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077449  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244825 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593108]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930419 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.1907745   0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.1907745   0.7402254  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.1312219  -0.1393016  -0.15244643 -0.19077377  0.74021703 -0.16592908]\n",
      "actions out: [-0.131223   -0.13930218 -0.15244685 -0.19077426  0.7402191  -0.16592982]\n",
      "actions out: [-0.1312231  -0.13930248 -0.15244696 -0.1907743   0.74021965 -0.16592994]\n",
      "actions out: [-0.13122101 -0.13930063 -0.15244563 -0.19077374  0.7402138  -0.16592854]\n",
      "actions out: [-0.13122027 -0.13929965 -0.15244494 -0.19077365  0.7402107  -0.165928  ]\n",
      "actions out: [-0.13121991 -0.13929926 -0.15244466 -0.19077362  0.7402094  -0.16592777]\n",
      "actions out: [-0.13122174 -0.13930091 -0.15244575 -0.1907742   0.7402145  -0.16592905]\n",
      "actions out: [-0.13122235 -0.13930176 -0.15244627 -0.19077423  0.74021703 -0.16592956]\n",
      "actions out: [-0.13122286 -0.13930233 -0.15244675 -0.19077425  0.74021894 -0.16592988]\n",
      "actions out: [-0.13122103 -0.13930066 -0.15244564 -0.19077368  0.7402138  -0.16592857]\n",
      "actions out: [-0.13122043 -0.13929982 -0.15244514 -0.19077362  0.74021137 -0.1659281 ]\n",
      "actions out: [-0.13121994 -0.13929926 -0.15244468 -0.19077365  0.7402095  -0.16592777]\n",
      "actions out: [-0.13122174 -0.1393009  -0.15244575 -0.19077419  0.7402145  -0.16592908]\n",
      "actions out: [-0.13122235 -0.13930179 -0.15244627 -0.19077423  0.74021703 -0.16592956]\n",
      "actions out: [-0.13122284 -0.13930231 -0.15244673 -0.19077425  0.74021894 -0.16592985]\n",
      "actions out: [-0.13122104 -0.13930066 -0.15244566 -0.19077368  0.7402139  -0.16592857]\n",
      "actions out: [-0.13122045 -0.13929981 -0.15244512 -0.19077362  0.74021137 -0.1659281 ]\n",
      "actions out: [-0.13121994 -0.13929926 -0.15244466 -0.19077365  0.74020946 -0.16592777]\n",
      "actions out: [-0.13122174 -0.1393009  -0.15244575 -0.1907742   0.7402145  -0.16592908]\n",
      "actions out: [-0.13122235 -0.13930176 -0.15244627 -0.19077423  0.74021703 -0.16592956]\n",
      "actions out: [-0.13122068 -0.13930035 -0.15244535 -0.19077365  0.74021256 -0.1659284 ]\n",
      "actions out: [-0.1312202  -0.13929962 -0.15244491 -0.19077362  0.7402106  -0.16592798]\n",
      "actions out: [-0.1312199  -0.13929923 -0.15244463 -0.19077365  0.7402094  -0.16592777]\n",
      "actions out: [-0.13122243 -0.13930152 -0.15244618 -0.19077437  0.74021655 -0.16592953]\n",
      "actions out: [-0.13122329 -0.1393027  -0.15244693 -0.19077443  0.74022    -0.16593018]\n",
      "actions out: [-0.13122396 -0.13930346 -0.15244755 -0.19077443  0.7402225  -0.16593063]\n",
      "actions out: [-0.13122441 -0.13930391 -0.15244797 -0.19077443  0.7402242  -0.16593087]\n",
      "actions out: [-0.1312247  -0.13930412 -0.15244822 -0.19077447  0.7402252  -0.16593105]\n",
      "actions out: [-0.13122381 -0.13930333 -0.15244767 -0.19077428  0.74022263 -0.16593042]\n",
      "actions out: [-0.13122441 -0.13930371 -0.15244795 -0.19077449  0.74022394 -0.16593078]\n",
      "actions out: [-0.13122453 -0.13930392 -0.15244806 -0.19077452  0.7402244  -0.16593093]\n",
      "actions out: [-0.13122462 -0.13930404 -0.15244813 -0.19077452  0.74022484 -0.16593099]\n",
      "actions out: [-0.13122466 -0.13930412 -0.15244818 -0.19077452  0.740225   -0.16593102]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.1907745   0.74022526 -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244825 -0.19077449  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244825 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930416 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122474 -0.13930418 -0.15244827 -0.19077452  0.7402254  -0.16593105]\n",
      "actions out: [-0.13122475 -0.13930418 -0.15244827 -0.19077452  0.7402253  -0.16593105]\n",
      "actions out: [-0.13122477 -0.13930416 -0.15244827 -0.19077452  0.74022526 -0.16593105]\n",
      "actions out: [-0.12687089 -0.13534208 -0.14982137 -0.18948127  0.72841436 -0.16308537]\n",
      "actions out: [-0.12384789 -0.13168862 -0.14813769 -0.18768294  0.7196785  -0.16111454]\n",
      "actions out: [-0.12289653 -0.13050786 -0.14663082 -0.1881404   0.7157774  -0.16043606]\n",
      "actions out: [-0.12248052 -0.13014674 -0.14596343 -0.18845905  0.71372956 -0.16019139]\n",
      "actions out: [-0.12218834 -0.12985568 -0.14557794 -0.18852067  0.71236396 -0.16002473]\n",
      "actions out: [-0.1222808  -0.12994623 -0.14561011 -0.1886206   0.7124306  -0.16008827]\n",
      "actions out: [-0.12244957 -0.13011079 -0.14574362 -0.18876122  0.7127579  -0.16020927]\n",
      "actions out: [-0.12198295 -0.12960973 -0.1458036  -0.18808098  0.71198297 -0.15996873]\n",
      "actions out: [-0.12089822 -0.1284022  -0.14568286 -0.18676515  0.71010137 -0.15939015]\n",
      "actions out: [-0.12011246 -0.12760203 -0.14523    -0.18607475  0.70877916 -0.15886775]\n",
      "actions out: [-0.11958628 -0.12711261 -0.1448895  -0.18564509  0.7078553  -0.15849647]\n",
      "actions out: [-0.11925956 -0.12680732 -0.14464223 -0.18539481  0.70725054 -0.15824467]\n",
      "actions out: [-0.11918829 -0.12673958 -0.1445269  -0.18536314  0.7070766  -0.15816045]\n",
      "actions out: [-0.11915935 -0.12671441 -0.14452665 -0.18533611  0.70703566 -0.1581429 ]\n",
      "actions out: [-0.11911624 -0.12667029 -0.14451744 -0.1852918   0.70697093 -0.15811798]\n",
      "actions out: [-0.1190924  -0.12664565 -0.14450553 -0.18526898  0.70693034 -0.15810245]\n",
      "actions out: [-0.11907893 -0.12663357 -0.14449772 -0.18525703  0.706906   -0.15809333]\n",
      "actions out: [-0.11906417 -0.1266206  -0.1444869  -0.18524526  0.70687747 -0.15808174]\n",
      "actions out: [-0.11905839 -0.12661517 -0.14448228 -0.18524082  0.7068661  -0.15807682]\n",
      "actions out: [-0.11905753 -0.1266142  -0.14448151 -0.18524021  0.7068643  -0.15807602]\n",
      "actions out: [-0.11905736 -0.126614   -0.14448136 -0.18524009  0.706864   -0.15807587]\n",
      "actions out: [-0.11905742 -0.12661329 -0.14448196 -0.18523957  0.7068625  -0.15807661]\n",
      "actions out: [-0.11905546 -0.12659574 -0.14449498 -0.18522552  0.70682466 -0.15809128]\n",
      "actions out: [-0.11906    -0.12654534 -0.14451806 -0.18519555  0.7067273  -0.15813026]\n",
      "actions out: [-0.1190811  -0.12614821 -0.14464459 -0.18490021  0.70589256 -0.15842217]\n",
      "actions out: [-0.11904732 -0.12618063 -0.14459115 -0.18505515  0.7061847  -0.15829426]\n",
      "actions out: [-0.1190395  -0.12636968 -0.1445445  -0.18523152  0.70659345 -0.15819097]\n",
      "actions out: [-0.1190458  -0.1264896  -0.144523   -0.1852868   0.7067689  -0.15815502]\n",
      "actions out: [-0.11905543 -0.12655386 -0.1445066  -0.18529312  0.70684105 -0.15813258]\n",
      "actions out: [-0.11910964 -0.12664866 -0.14449382 -0.18531577  0.70694274 -0.15812594]\n",
      "actions out: [-0.11910584 -0.12666038 -0.14450225 -0.18529095  0.7069461  -0.15811202]\n",
      "actions out: [-0.11908837 -0.12664293 -0.14449982 -0.18526809  0.7069201  -0.15809876]\n",
      "actions out: [-0.11907632 -0.12663105 -0.14449438 -0.18525581  0.70689976 -0.15809044]\n",
      "actions out: [-0.11906899 -0.12662457 -0.14449015 -0.18524925  0.7068867  -0.15808532]\n",
      "actions out: [-0.11906076 -0.12661736 -0.1444841  -0.18524268  0.70687073 -0.15807882]\n",
      "actions out: [-0.11905801 -0.1266147  -0.14448191 -0.18524058  0.7068653  -0.15807644]\n",
      "actions out: [-0.11905747 -0.12661414 -0.14448147 -0.18524016  0.70686424 -0.15807596]\n",
      "actions out: [-0.11905736 -0.12661402 -0.14448136 -0.1852401   0.70686406 -0.15807587]\n",
      "actions out: [-0.11905733 -0.12661399 -0.14448133 -0.18524007  0.70686394 -0.15807584]\n",
      "actions out: [-0.11905732 -0.12661397 -0.14448133 -0.18524006  0.70686394 -0.15807584]\n",
      "actions out: [-0.11905731 -0.12661396 -0.14448133 -0.18524005  0.7068639  -0.15807584]\n",
      "actions out: [-0.11929945 -0.12683494 -0.14450456 -0.18548821  0.70721596 -0.15820387]\n",
      "actions out: [-0.1198528  -0.12735254 -0.14462993 -0.18603493  0.7080409  -0.15851495]\n",
      "actions out: [-0.11968657 -0.12723257 -0.14478469 -0.18581982  0.7079222  -0.15848878]\n",
      "actions out: [-0.11956406 -0.12708618 -0.14474128 -0.1856894   0.70774096 -0.15841717]\n",
      "actions out: [-0.11960005 -0.127117   -0.1447193  -0.18573219  0.70777816 -0.15843177]\n",
      "actions out: [-0.11995815 -0.12745339 -0.14475289 -0.18609771  0.7082816  -0.15861887]\n",
      "actions out: [-0.12004784 -0.12756118 -0.14484224 -0.18617485  0.70845515 -0.15868911]\n",
      "actions out: [-0.11997934 -0.12749167 -0.1448895  -0.18608451  0.7084004  -0.15867132]\n",
      "actions out: [-0.1210079  -0.1285063  -0.14493448 -0.18733384  0.7099506  -0.15923384]\n",
      "actions out: [-0.12168025 -0.12930565 -0.1452495  -0.18807031  0.7112228  -0.15966949]\n",
      "actions out: [-0.12206727 -0.12971976 -0.14546609 -0.1884374   0.7119791  -0.15993163]\n",
      "actions out: [-0.12208971 -0.12973133 -0.14564112 -0.18833843  0.7121076  -0.15998888]\n",
      "actions out: [-0.12228986 -0.12992606 -0.14567909 -0.18856768  0.71246284 -0.16011882]\n",
      "actions out: [-0.12141318 -0.12898561 -0.1457656  -0.18733864  0.71098137 -0.15964574]\n",
      "actions out: [-0.12174206 -0.12929165 -0.14541204 -0.18797441  0.71143824 -0.15977257]\n",
      "actions out: [-0.12200516 -0.12965307 -0.1454993  -0.18831663  0.7119077  -0.15992957]\n",
      "actions out: [-0.12215155 -0.12981065 -0.14558473 -0.18845792  0.71219045 -0.16002163]\n",
      "actions out: [-0.12226035 -0.12991808 -0.14562455 -0.18857594  0.7123887  -0.16008699]\n",
      "actions out: [-0.12241951 -0.13008201 -0.14572726 -0.18871988  0.7126933  -0.1601972 ]\n",
      "actions out: [-0.12187465 -0.12949292 -0.14579056 -0.18794377  0.71179336 -0.159906  ]\n",
      "actions out: [-0.12124126 -0.12875709 -0.14562243 -0.18717715  0.7106486  -0.15952629]\n",
      "actions out: [-0.12165882 -0.12921481 -0.1453523  -0.187911    0.71128184 -0.15971845]\n",
      "actions out: [-0.12199085 -0.12964195 -0.14546292 -0.18832909  0.71186405 -0.15990993]\n",
      "actions out: [-0.12218755 -0.12985262 -0.14555426 -0.18853442  0.7122305  -0.16002843]\n",
      "actions out: [-0.12234192 -0.13000672 -0.14565851 -0.18866391  0.71253556 -0.16013673]\n",
      "actions out: [-0.12246723 -0.13012844 -0.14576042 -0.18877555  0.71279174 -0.16022259]\n",
      "actions out: [-0.12248542 -0.13015108 -0.14577834 -0.18879208  0.7128306  -0.16023731]\n",
      "actions out: [-0.12248913 -0.13015582 -0.14578244 -0.1887951   0.7128386  -0.16024032]\n",
      "actions out: [-0.12249131 -0.13015793 -0.14578375 -0.18879808  0.71284324 -0.16024143]\n",
      "actions out: [-0.12242696 -0.13009584 -0.14577907 -0.18869345  0.71272117 -0.1602149 ]\n",
      "actions out: [-0.1222283  -0.12987508 -0.14576991 -0.18843181  0.7123903  -0.16010344]\n",
      "actions out: [-0.12197717 -0.12959167 -0.1457132  -0.18812747  0.7119532  -0.15995544]\n",
      "actions out: [-0.122058   -0.12967601 -0.14560711 -0.18830289  0.7120569  -0.15998471]\n",
      "actions out: [-0.12218223 -0.1298328  -0.14561653 -0.18847477  0.7122657  -0.16005298]\n",
      "actions out: [-0.12211824 -0.12976575 -0.1456657  -0.18835978  0.712175   -0.16002157]\n",
      "actions out: [-0.12222172 -0.12986316 -0.145645   -0.1885045   0.7123415  -0.16007647]\n",
      "actions out: [-0.1217211  -0.1293235  -0.14573178 -0.18777597  0.7115157  -0.15981013]\n",
      "actions out: [-0.12195503 -0.12954365 -0.14551824 -0.18820931  0.7118482  -0.15991053]\n",
      "actions out: [-0.12210531 -0.12975621 -0.14558126 -0.18839674  0.7121194  -0.16000292]\n",
      "actions out: [-0.12219156 -0.12984622 -0.14563185 -0.18847887  0.71228176 -0.16005558]\n",
      "actions out: [-0.12170938 -0.12931173 -0.14569196 -0.18778805  0.7114827  -0.15979275]\n",
      "actions out: [-0.12179603 -0.12936755 -0.14555179 -0.18797538  0.71159375 -0.15982577]\n",
      "actions out: [-0.12145881 -0.12903191 -0.14557189 -0.18752398  0.71101916 -0.15963987]\n",
      "actions out: [-0.12105205 -0.12856081 -0.14545402 -0.18703713  0.7102717  -0.15938765]\n",
      "actions out: [-0.12129565 -0.128828   -0.14527725 -0.18748362  0.71064335 -0.15949523]\n",
      "actions out: [-0.12085951 -0.12838183 -0.1454082  -0.18684377  0.70992225 -0.15927696]\n",
      "actions out: [-0.12110405 -0.12861055 -0.14521122 -0.18726285  0.7102826  -0.1593697 ]\n",
      "actions out: [-0.12152257 -0.12910694 -0.14529443 -0.18780331  0.7110197  -0.15961367]\n",
      "actions out: [-0.12158316 -0.1291838  -0.14545684 -0.18777964  0.7111947  -0.15967974]\n",
      "actions out: [-0.1217154  -0.12930806 -0.1454519  -0.18795222  0.7114239  -0.15975419]\n",
      "actions out: [-0.1218613  -0.12947063 -0.14554277 -0.18809076  0.7117054  -0.15985599]\n",
      "actions out: [-0.12152637 -0.12910391 -0.1455986  -0.18759976  0.7111471  -0.1596781 ]\n",
      "actions out: [-0.12164921 -0.1292165  -0.14545381 -0.18784802  0.7113152  -0.15972582]\n",
      "actions out: [-0.12071974 -0.12824982 -0.14553984 -0.18664204  0.7097755  -0.15925562]\n",
      "actions out: [-0.12072671 -0.12817253 -0.14520258 -0.18673554  0.7096154  -0.15915409]\n",
      "actions out: [-0.12104323 -0.1285701  -0.14516401 -0.18722205  0.71015155 -0.15932888]\n",
      "actions out: [-0.12128993 -0.12886135 -0.1452728  -0.1875013   0.7106206  -0.15948167]\n",
      "actions out: [-0.12114836 -0.1286963  -0.14534752 -0.18725951  0.7104034  -0.15941012]\n",
      "actions out: [-0.1215019  -0.12905675 -0.14534855 -0.18772323  0.71102643 -0.15961772]\n",
      "actions out: [-0.12171493 -0.12931864 -0.14545187 -0.18795615  0.711425   -0.15975851]\n",
      "actions out: [-0.12196412 -0.1295912  -0.14549787 -0.18826127  0.7118597  -0.15990457]\n",
      "actions out: [-0.12198045 -0.12961411 -0.14559378 -0.18822362  0.71192014 -0.15992883]\n",
      "actions out: [-0.12185226 -0.12945734 -0.14563724 -0.18801372  0.7117198  -0.15986729]\n",
      "actions out: [-0.1214943  -0.1290551  -0.14560023 -0.18754774  0.71109325 -0.15966293]\n",
      "actions out: [-0.1216347  -0.12920044 -0.14545415 -0.18782663  0.7112902  -0.15972066]\n",
      "actions out: [-0.12136043 -0.12893012 -0.14550169 -0.18744189  0.710829   -0.15957007]\n",
      "actions out: [-0.12068736 -0.12818879 -0.14541492 -0.18664421  0.7096821  -0.15919942]\n",
      "actions out: [-0.12102487 -0.12851186 -0.14517777 -0.18716802  0.71013    -0.15932223]\n",
      "actions out: [-0.12087183 -0.12839302 -0.14530239 -0.18690719  0.7098971  -0.15925366]\n",
      "actions out: [-0.12114032 -0.12866749 -0.14519982 -0.18733038  0.7103415  -0.15938589]\n",
      "actions out: [-0.12093925 -0.12846394 -0.14532629 -0.18698679  0.7100271  -0.15929016]\n",
      "actions out: [-0.12081548 -0.12829186 -0.14529645 -0.18681785  0.70980424 -0.15921897]\n",
      "actions out: [-0.12111752 -0.1286363  -0.14520033 -0.18729645  0.71030635 -0.15937707]\n",
      "actions out: [-0.12094208 -0.12846805 -0.14533667 -0.18698259  0.71003824 -0.15929794]\n",
      "actions out: [-0.12119245 -0.12871967 -0.1452337  -0.187378    0.71044856 -0.15942228]\n",
      "actions out: [-0.12141844 -0.12899266 -0.14533943 -0.18763007  0.7108764  -0.15956855]\n",
      "actions out: [-0.12112952 -0.12866716 -0.14544803 -0.18716145  0.7104055  -0.15942279]\n",
      "actions out: [-0.12130766 -0.12883775 -0.14531387 -0.18747687  0.7106779  -0.15950423]\n",
      "actions out: [-0.12149038 -0.12906778 -0.14539504 -0.18768714  0.71102095 -0.15962309]\n",
      "actions out: [-0.12113919 -0.1286798  -0.14545715 -0.18716845  0.71042556 -0.15943173]\n",
      "actions out: [-0.12030523 -0.12781313 -0.14530192 -0.18627767  0.709089   -0.15897593]\n"
     ]
    }
   ],
   "source": [
    "for i  in range(len(atari_env.frame_buffer)):\n",
    "    print(\"actions out: {}\".format(atari_env.frame_buffer[i].action_array))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -0.8604, target: 3.0\n",
      "reward: 1.3911, target: 4.0\n",
      "reward: -1.1576, target: 3.0\n",
      "reward: -0.0128, target: 3.0\n",
      "reward: -0.4280, target: 3.0\n",
      "reward: -0.4917, target: 3.0\n",
      "reward: -0.8007, target: 3.0\n",
      "reward: -1.0440, target: 3.0\n",
      "reward: -0.7486, target: 3.0\n",
      "reward: 0.5455, target: 4.0\n",
      "reward: -0.7897, target: 3.0\n",
      "reward: 0.6045, target: 4.0\n",
      "reward: -0.6514, target: 3.0\n",
      "reward: -1.1364, target: 3.0\n",
      "reward: 0.8160, target: 4.0\n",
      "reward: 0.3267, target: 4.0\n",
      "reward: 0.5948, target: 4.0\n",
      "reward: -1.1296, target: 3.0\n",
      "reward: 1.0987, target: 4.0\n",
      "reward: -0.2401, target: 3.0\n",
      "reward: -0.1402, target: 3.0\n",
      "reward: -0.9419, target: 3.0\n",
      "reward: -0.3903, target: 3.0\n",
      "reward: -1.0405, target: 3.0\n",
      "reward: -1.1576, target: 3.0\n",
      "reward: -0.9636, target: 3.0\n",
      "reward: 1.4699, target: 4.0\n",
      "reward: -0.2732, target: 3.0\n",
      "reward: 2.4107, target: 4.0\n",
      "reward: 0.1405, target: 3.0\n",
      "reward: -0.1791, target: 3.0\n",
      "reward: 0.3095, target: 4.0\n",
      "reward: -0.3093, target: 3.0\n",
      "reward: 0.2978, target: 4.0\n",
      "reward: 0.9062, target: 4.0\n",
      "reward: -1.1576, target: 3.0\n",
      "reward: 0.6974, target: 4.0\n",
      "reward: 0.1807, target: 3.0\n",
      "reward: 0.5422, target: 4.0\n",
      "reward: -0.0175, target: 3.0\n",
      "reward: -0.6587, target: 3.0\n",
      "reward: -0.3255, target: 3.0\n",
      "reward: 1.5512, target: 4.0\n",
      "reward: -1.0474, target: 3.0\n",
      "reward: -1.1576, target: 3.0\n",
      "reward: -1.1576, target: 3.0\n",
      "reward: 0.7548, target: 4.0\n",
      "reward: -0.8467, target: 3.0\n",
      "reward: 0.0591, target: 3.0\n",
      "reward: -1.0977, target: 3.0\n",
      "[ 0.  0.  0. 34. 16.  0.]\n"
     ]
    }
   ],
   "source": [
    "frame_batch, target_batch, reward_batch, actions_batch = get_train_batch(atari_env, 50)\n",
    "\n",
    "target_tally = np.zeros(6)\n",
    "\n",
    "for i  in range(len(reward_batch)):\n",
    "    print(\"reward: {:.4f}, target: {}\".format(reward_batch[i], target_batch[i]))\n",
    "    target_tally[int(target_batch[i])] += 1\n",
    "    \n",
    "print(target_tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
